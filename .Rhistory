m <- 20
x <- c(1:n)
y <- c(1:m)
# use importance sampling approach to approximate CDF. Assume x and y follow normal distributions
Yx <- rnorm(n, mean = 0, sd = 1)
Yy <- rnorm(m, mean = 0, sd = 1)
cdfx <- numeric(length(x))
cdfy <- numeric(length(y))
for (i in 1:length(x)){
gx <- x[i]*exp(-(Yx*x[i])^2/2)
cdfx[i]<-mean(gx)/sqrt(2*pi)+0.5
gy <- x[i]*exp(-(Yy*x[i])^2/2)
cdfy[i]<-mean(gy)/sqrt(2*pi)+0.5
}
cdfx
cdfy
for (i in 1:length(x)){
gx <- x[i]*exp(-(Yx*x[i])^2/2)
cdfx[i]<-mean(gx)/sqrt(2*pi)+0.5
gy <- y[i]*exp(-(Yy*x[i])^2/2)
cdfy[i]<-mean(gy)/sqrt(2*pi)+0.5
}
cdfx
cdfy
for (i in 1:length(x)){
gx <- x[i]*exp(-(Yx*x[i])^2/2)
cdfx[i]<-mean(gx)/sqrt(2*pi)+0.5
gy <- y[i]*exp(-(Yy*y[i])^2/2)
cdfy[i]<-mean(gy)/sqrt(2*pi)+0.5
}
cdfx
cdfy
m <- 10
for (i in 1:length(x)){
gx <- x[i]*exp(-(Yx*x[i])^2/2)
cdfx[i]<-mean(gx)/sqrt(2*pi)+0.5
gy <- y[i]*exp(-(Yy*y[i])^2/2)
cdfy[i]<-mean(gy)/sqrt(2*pi)+0.5
}
cdfy
cdfx
for (i in 1:length(x)){
gx <- x[i]*exp(-(Yx*x[i])^2/2)
cdfx[i]<-mean(gx)/sqrt(2*pi)
gy <- y[i]*exp(-(Yy*y[i])^2/2)
cdfy[i]<-mean(gy)/sqrt(2*pi)
}
cdfx
cdfy
xy <- x + y
xy
xy <- c(x,y)
xy
boot.samples = matrix(sample(xy,
size = B * (n+m), replace = TRUE), B, n)
boot.samples
xy <- as.matrix(x,y)
xy
x <- c(1:n)
y <- c(1:m)
xy
x
y
xy <- as.matrix(nrow = 10, ncol =2)
xy <- as.matrix(rep(1:10,2),nrow = 10, ncol =2)
xy
xy <- as.matrix(1:20,nrow = 10, ncol =2)
xy
xy <- as.matrix(1:20, nrow = 10, ncol = 2)
xy
xy <- cbind(1:10, 1:10)
xy
boot.samples = matrix(sample(xy,
size = B * (n+m), replace = TRUE), B, n)
boot.statistics <- cbind(1:10, 1:10)
boot.statistics
boot.statistics[1][2]
boot.statistics[1,2]
boot.statistics[2,2]
boot.statistics[2,3]
boot.statistics[3,2]
boot.samples = matrix(sample(xy,
size = B * (n+m), replace = TRUE), B, n)
boot.samples
boot.samplesx = matrix(sample(x,
size = B * (n), replace = TRUE), B, n)
boot.samplesx
B = 1000 # number of bootstrap replicates
n = length(time)
samples <- time - mean(time) - 29.61
boot.samples = matrix(sample(samples,
size = B * n, replace = TRUE), B, n)
boot.statistics = apply(boot.samples, 1, t.test)
boot.statistics
boot.samplesx = matrix(sample(x,
size = B * (n), replace = TRUE), B, n)
boot.samplesy = matrix(sample(y,
size = B * (m), replace = TRUE), B, m)
for(i in (1:1000)){
boot.statistics[i] <- t.test(boot.samplesx[i], boot.samplesy[i])
}
boot.samplesx
boot.samplesx[1]
boot.samplesx[2]
boot.samplesx[3]
for(i in (1:1000)){
boot.statistics[i] <- t.test(boot.samplesx, boot.samplesy)
}
boot.statistics[1]
boot.statistics[2]
boot.statistics[3]
boot.statistics[4]
boot.samplesx = matrix(sample(cdfx,
size = B * (n), replace = TRUE), B, n)
boot.samplesy = matrix(sample(cdfy,
size = B * (m), replace = TRUE), B, m)
ttestfunction(boot.samplesx, boot.samplesy)
ttestfunction <- function(x, y){
return(t.test(x,y))
}
ttestfunction(boot.samplesx, boot.samplesy)
boot.statistics <- apply(boot.samplesx, ttestfunction, y=boot.samplesy)
boot.statistics <- sapply(boot.samplesx, ttestfunction, y=boot.samplesy)
boot.samplesx = matrix(sample(cdfx,
size = B * (n), replace = TRUE), B, n)
boot.samplesy = matrix(sample(cdfy,
size = B * (m), replace = TRUE), B, m)
ttestfunction <- function(x, y){
return(t.test(x,y))
}
boot.statistics <- sapply(boot.samplesx, ttestfunction, y=boot.samplesy)
boot.statistics <- mapply(ttestfunction, boot.samplesx, boot.samplesy)
boot.samplesx
cdfx
boot.statistics <- mapply(ttestfunction, boot.samplesx, boot.samplesy)
boot.statistics <- apply(ttestfunction, boot.samplesx, boot.samplesy)
boot.statistics <- mapply(ttestfunction, boot.samplesx, boot.samplesy)
boot.statistics <- mapply(ttestfunction, 1, boot.samplesx, boot.samplesy)
B = 1000 # number of bootstrap replicates
n = length(time)
samples <- time - mean(time) - 29.61
boot.samples = matrix(sample(samples,
size = B * n, replace = TRUE), B, n)
boot.samples
apply(boot.samples, 1, t.test)
boot.samplesx = matrix(sample(cdfx,
size = B * (n), replace = TRUE), B, n)
boot.samplesy = matrix(sample(cdfy,
size = B * (m), replace = TRUE), B, m)
ttestfunction <- function(x, y){
return(t.test(x,y))
}
boot.statisticsxy <- mapply(ttestfunction, boot.samplesx, boot.samplesy)
t.test(bootsamplesx[1], bootsamplesy[1])
t.test(boot.samplesx[1], boot.samplesy[1])
boot.samples[1]
boot.samples[,1]
t.test(boot.samplesx[,1], boot.samplesy[,1])
boot.samplesx = matrix(sample(cdfx,
size = B * (n), replace = TRUE), B, n)
boot.samplesy = matrix(sample(cdfy,
size = B * (m), replace = TRUE), B, m)
for(i in (1:10)){
boot.statisticsxy <- t.test(boot.samplesx[,i], boot.samplesy[,i])
}
pvalues <- c()
for(i in (1:B)){
pvalues[i] <- boot.statistics[[i]]$p.value
}
for(i in (1:B)){
pvalues[i] <- boot.statisticsxy[[i]]$p.value
}
boot.statisticsxy
boot.statisticsxy <- c()
for(i in (1:10)){
boot.statisticsxy[i] <- t.test(boot.samplesx[,i], boot.samplesy[,i])
}
boot.statisticsxy[1]
boot.statisticsxy[2]
for(i in (1:10)){
boot.statisticsxy <- t.test(boot.samplesx[,i], boot.samplesy[,i])
}
pvalues <- c()
for(i in (1:10)){
boot.statisticsxy <- t.test(boot.samplesx[,i], boot.samplesy[,i])
pvalues[i] <- boot.statisticsxy$p.value
}
pvalues
bootapproximate = mean(pvalues) # bootstrap p value approximate
bootapproximate
print(biasestimate)
```{r}
mixturemodel <- function(z, mu1=7,mu2=10,sigma1=0.5,sigma2=0.5){
return(0.7*dnorm(z, mu1, sigma1) + 0.3*dnorm(z, mu2, sigma2))
}
metropolisHastingsMixture <- function(z, chainLength, target, sigma1, burnin){
chain <- c()
for(i in ((burnin):chainLength)){
# do not include the burn in values
proposed = rnorm(1,z,sigma1)
if(log(runif(1))<log(min(1,target(proposed)/target(z)))){
# implement stopping criterion
chain[i] <- proposed
# set new value in chain
}
else{
chain[i] <- z
# keep z value for the chain
}
}
return(chain)
}
chain1 <- metropolisHastingsMixture(0,10000,mixturemodel,0.01,3)
plot(chain1, type = "l")
# trace plot
hist(chain1)
lines(density(chain1[3:10000]), lwd = 2, col = "blue")
install.packages('devtools')
checkIfInternalRhymePrint <- apply(iterationForRhymes, 1, function(x){checkIfInternalRhyme(convertToVectors2[[x]], rhymeSchemes[[x]])})
iterationForRhymes <- 1:length(rhymeSchemes)
mcf <- readHumdrum('.*rap')
library(humdrumR)
mcf <- readHumdrum('.*rap')
getwd()
setwd("/Users/robbyice/Desktop/GTPortfolio/humdrumR")
mcf <- readHumdrum('.*rap')
spinePipe(mcf, 2:8, 1) -> mcf[rev(c('Stress', 'Tone', 'Break', 'Rhyme', 'IPA', 'Lyrics', 'Hype'))]
segments <- function(x, reverse = FALSE) {
if (!is.logical(x)) x <- c(TRUE, head(x, -1L) != tail(x, -1L))
if (reverse) x <- rev(x)
x <- cumsum(x)
if (reverse) {
x <- rev(-x) + max(x) + 1
}
x
}
mcf$Token %hum>% c(~segments(Break %in% c('3', '4','5')), by ~ File) -> mcf$Phrase
mcf$Token %hum<% c(~list(paste(Lyrics, collapse = ' ')), by ~ File ~ Phrase)
rhymeSchemes <- mcf$Token %hum<% c(~list(Rhyme), by ~ File ~ Phrase)
iterationForRhymes <- 1:length(rhymeSchemes)
iterationForRhymes <- cbind(iterationForRhymes)
checkIfInternalRhyme <- function(pattern2, wholeString2){
save3 <- list(TRUE)
if(length(pattern2) > 0){
iteration <- 1:length(pattern2)
iteration <- cbind(iteration)
if(length(pattern2) > 1){
save3 <- apply(iteration, 1, function(x){
if(grepl("\\(", pattern2[x]) == TRUE){
pattern2[x] <- paste(pattern2[x], ")")
}
if(grepl("\\[", pattern2[x]) == TRUE){
pattern2[x] <- paste(pattern2[x], "]")
}
if(length(grep(pattern2[x], wholeString2)) >= 1){
return(TRUE)
}
else{
return(FALSE)
}
}
)
}
else{
save3 <- list(FALSE)
}
if(length(which(save3) == TRUE) >= 1){
return(TRUE)
}
print(save3)
}
if(length(pattern2) == 0){
return(FALSE)
}
}
getIndicesOfLetters <- function(string){
if(length(string)<1){
return(0)
}
else{
return(which(string != "."))
}
}
letters <- apply(iterationForRhymes, 1, function(x){getIndicesOfLetters(rowRhymeSchemes[x,]$rhymeSchemes)})
letters <- cbind(letters)
library(humdrumR)
# pacCaliLoveData <- readHumdrum("2pac_CaliforniaLove.rap")
# pacHowDoUWantItData <- readHumdrum("2pac_HowDoUWantIt.rap")
# census(pacCaliLoveData)
# reference(pacCaliLoveData)
# spines(pacCaliLoveData)
# interpretations(pacCaliLoveData)
# # error - object 'exclusive' not found
# sections(pacCaliLoveData)
# # error - could not find function 'sections'
# summary(pacCaliLoveData)
# # error - code stops at interpretations
# interpretations(pacHowDoUWantItData)
# # error
# sections(pacHowDoUWantItData)
# # error
# summary(pacHowDoUWantItData)
# # error - code stops at interpretations
#
# centCandyShopData <- readHumdrum("50Cent_CandyShop.rap")
# census(centCandyShopData)
# reference(centCandyShopData)
# spines(centCandyShopData)
# interpretations(centCandyShopData)
# sections(centCandyShopData)
# summary(centCandyShopData)
#
# # seems that the functions interpretations and sections are not working for the rap datasets.
#
# rapData <- readHumdrum('.*rap')
#
# census(rapData)
# reference(rapData)
# spines(rapData)
# interpretations(rapData)
# sections(rapData)
# summary(rapData)
#
# filterhumdrum(rapData)
# rapData[2]
library(humdrumR)
segments <- function(x, reverse = FALSE) {
if (!is.logical(x)) x <- c(TRUE, head(x, -1L) != tail(x, -1L))
if (reverse) x <- rev(x)
x <- cumsum(x)
if (reverse) {
x <- rev(-x) + max(x) + 1
}
x
}
mcf <- readHumdrum('.*rap')
spinePipe(mcf, 2:8, 1) -> mcf[rev(c('Stress', 'Tone', 'Break', 'Rhyme', 'IPA', 'Lyrics', 'Hype'))]
mcf$Token %hum>% c(~segments(Break %in% c('3', '4','5')), by ~ File) -> mcf$Phrase
mcf$Token %hum<% c(~list(paste(Lyrics, collapse = ' ')), by ~ File ~ Phrase)
rhymeSchemes <- mcf$Token %hum<% c(~list(Rhyme), by ~ File ~ Phrase)
rhymeSchemes3 <- unlist(rhymeSchemes[[1000]])
occurrences <- table(rhymeSchemes3)
countFrequencies <- function(element){
frequencyCount <- unlist(element)
frequencyCount <- table(frequencyCount)
return(frequencyCount)
}
recordMoreThanOneInstance <- function(table){
saveList <- unlist(table)
saveList <- as.data.frame(saveList)
saveList <- t(saveList)
determine <- which(saveList > 1)
saveList <- as.data.frame(saveList)
internalRhymes <- saveList[determine]
return(internalRhymes)
}
# 1. look for most common number of internal rhymes in each line
# 2. look to see if most occur in the first or second half of the line for example - is there a difference in perception there? Maybe the longer an artist goes without rhyming,
#    the more likely you are to catch the internal rhyme, or there is a greater reaction (brain or implicit reaction). Theory is that if internal rhyme occurs earlier in the line
#    the listener is not ready for it and it cannot be processed fully because the person has not completely focused in on the audio. Each line sort of starts a new processing
#    scheme/event?
# 3. is it easier to perceive an internal rhyme with the rhymes sort of far apart if the song were to be rehearsed such that the line was broken up into two lines and the rhymes
#    occurred at the end of each line?
#    keep diving into it more. naming these things.
#   initial experiment - internal rhyme. When do you notice an internal rhyme. bring in statistical thing. 1. Computational  - doing analyses (improving or
#   expanding MCFlow. Start writing abstract. Collab on overleaf. Two challenges - what are the stimuli? Other - what is the task? Both EEG and behavioral.
#   first 2 hypotheses - likelihood of rhyme and perception of it. can manipulate where we put it.
# 4. look at likelihood of internal rhymes in a similar way as nat's theory with phonemes -- is an internal rhyme more likely to be perceived as a rhyme if it is an internal rhyme
#    structure that is not seen very often in rap music?
# 5. Is a rhyme perceived if the artist puts intonation on the end word of a line and the first word on the next line technically rhymes with that word but they
#    say it in a "normal" talking voice. What if they put intonation on the first word, it rhymes with the last word but there's no intonation on it.
# 6. Compare rhymes in a normal talking voice and rapping voice.
# 7. What is largest difference between # of non-rhyming words and the max # of internal rhymes in any given line? How does the length of syllables of this line compare to previous?
#    How often can person detect the rhyme there? Once you go past the amount of syllables as the previous line, we don't know when the rhyme is going to come. Maybe the person's
#    level of attention decreases as the line moves forward and then an internal rhyme doesn't catch their attention - or maybe the opposite. In function below.
#    Can also look at how the distance between two internal rhyming words interacts with the number of non-rhyming words occurring before the first instance of an internal rhyming word
#    since there has been so much time passing without a rhyme. Ties back to original theory where which is more likely? Becomes increasingly unlikely to hear a rhyme. Compare
#    to when there's a rhyme at the end of one line and also the beginning of next one.
# 8. Does perception of rhyme differ when you flip the order of a double internal rhyme? I.e. is ab ab perceived the same or in a similar way as ba ab. I.e. inverse. Same for jJj and JjJ?
recordFreqDifference <- function(table){
if(NCOL(table$internalRhymesList) == 0){
return(0)
}
# record frequency difference between non rhyming words and the most frequent internal rhyme
df <- as.data.frame(table)
nonRhymingWordFrequency <- df[,1]
vector <- which(colnames(table$internalRhymesList) != ".")
if(length(vector) >= 1){
maxInternalRhyme <- max(table$internalRhymesList[,vector])
maxInternalRhymeIndex <- which(table$internalRhymesList == maxInternalRhyme)
difference <- nonRhymingWordFrequency - maxInternalRhyme
}
else{
return(0)
}
return(difference)
}
# test function
df2 <- as.data.frame(frequencyTables[[968]])
determine <- which(df2$Freq > 1)
internalRhymes <- df2$frequencyCount[determine]
# implement functions
rhymeSchemes <- mcf$Token %hum<% c(~list(Rhyme), by ~ File ~ Phrase)
iteration <- 1:length(rhymeSchemes)
iteration <- cbind(iteration)
df <- rbind(rhymeSchemes)
df <- as.data.frame(t(df))
frequencyTables <- apply(iteration, 1, function(x){countFrequencies(df[x,1])})
frequencyTablesDataFrame <- cbind(frequencyTables)
# frequencyTablesDataFrame <- as.data.frame(frequencyTablesDataFrame)
internalRhymesList <- apply(iteration, 1, function(x){recordMoreThanOneInstance(frequencyTablesDataFrame[x][1])})
internalRhymesListDataFrame <- rbind(internalRhymesList)
internalRhymesListDataFrame <- as.data.frame(internalRhymesListDataFrame)
save <- apply(iteration, 1, function(x){as.data.frame(internalRhymesListDataFrame[1,x])})
# internalRhymesListDataFrame <- t(internalRhymesListDataFrame)
findMaxDifference <- apply(iteration, 1, function(x){recordFreqDifference(internalRhymesListDataFrame[1,x])})
maxDifference <- max(findMaxDifference)
# findMaxDifference <- apply(iteration, 1, function(x){recordFreqDifference(internalRhymesListDataFrame[1,x]$internalRhymesList)})
tableWithMaxDifference <- which(findMaxDifference == maxDifference)
findTableWithMaxDifference <- frequencyTables[tableWithMaxDifference]
# test summary functions again
# library(humdrumR)
# mcf <- readHumdrum('.*rap')
# census(mcf)
# reference(mcf)
# spines(mcf)
# interpretations(mcf)
# sections(mcf)
# summary(mcf)
# largest distance between two internal rhymes
save <- rowRhymeSchemes[5,]$rhymeSchemes
indicesOfLetters <- which(save != ".")
letters <- save[indicesOfLetters]
# gsub("\\s*\\([^\\)]","s",as.character(rowRhymeSchemes[5,]$rhymeSchemes))
# gsub("\\s*\\)","t",as.character(rowRhymeSchemes[5,]$rhymeSchemes))
save2 <- replaceWithRepeating(rowRhymeSchemes[5,]$rhymeSchemes)
indices <- grep("bt", save2)
# function
rowRhymeSchemes <- cbind(rhymeSchemes)
replaceWithRepeating <- function(string){
save <- gsub("\\s*\\([^\\)]","s",as.character(string))
save <- gsub("\\s*\\)","t",as.character(save))
# this allows R to read these as repeating rhymes
return(save)
}
getIndices <- function(pattern1, wholeString){
if(length(pattern1) > 0){
iteration <- 1:length(pattern1)
iteration <- cbind(iteration)
save <- apply(iteration, 1, function(x){ grep(pattern1[x], wholeString)})
print(1)
return(save)
}
else{
return(-1)
}
}
getIndicesOfLetters <- function(string){
if(length(string)<1){
return(0)
}
else{
return(which(string != "."))
}
}
iteration <- 1:length(indicesOfLetters)
iterationForRhymes <- 1:length(rhymeSchemes)
iterationForRhymes <- cbind(iterationForRhymes)
letters <- apply(iterationForRhymes, 1, function(x){getIndicesOfLetters(rowRhymeSchemes[x,]$rhymeSchemes)})
letters <- cbind(letters)
getPatterns <- apply(iterationForRhymes, 1, function(x){return(rowRhymeSchemes[x,]$rhymeSchemes[letters[x,]$letters])})
replaceWithRepeatingPrint <- apply(iterationForRhymes, 1, function(x){replaceWithRepeating(getPatterns[[x]])})
renameRhymeSchemes <- apply(iterationForRhymes, 1, function(x){replaceWithRepeating(rowRhymeSchemes[x,]$rhymeSchemes)})
convertToVectors <- apply(iterationForRhymes, 1, function(x){return(as.vector(replaceWithRepeatingPrint[[x]]))})
convertToVectors2 <- apply(iterationForRhymes, 1, function(x){return(as.vector(getPatterns[[x]]))})
checkIfInternalRhyme <- function(pattern2, wholeString2){
save3 <- list(TRUE)
if(length(pattern2) > 0){
iteration <- 1:length(pattern2)
iteration <- cbind(iteration)
if(length(pattern2) > 1){
save3 <- apply(iteration, 1, function(x){
if(grepl("\\(", pattern2[x]) == TRUE){
pattern2[x] <- paste(pattern2[x], ")")
}
if(grepl("\\[", pattern2[x]) == TRUE){
pattern2[x] <- paste(pattern2[x], "]")
}
if(length(grep(pattern2[x], wholeString2)) >= 1){
return(TRUE)
}
else{
return(FALSE)
}
}
)
}
else{
save3 <- list(FALSE)
}
if(length(which(save3) == TRUE) >= 1){
return(TRUE)
}
print(save3)
}
if(length(pattern2) == 0){
return(FALSE)
}
}
checkIfInternalRhymePrint <- apply(iterationForRhymes, 1, function(x){checkIfInternalRhyme(convertToVectors2[[x]], rhymeSchemes[[x]])})
# getIndicesPrint <- apply(iterationForRhymes, 1, function(x){getIndices(convertToVectors[[x]], renameRhymeSchemes[[x]])})
# printDistance <- apply(iteration, 1, function(x){grep(rowRhymeSchemes[x], rowRhymeSchemes[5,]$rhymeSchemes)})
